{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2.1 - Data Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "aiobotocore 2.13.3 requires botocore<1.34.163,>=1.34.70, but you have botocore 1.36.2 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires torch<2.4,>=2.2, but you have torch 2.4.1.post100 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires torch<2.4,>=2.2, but you have torch 2.4.1.post100 which is incompatible.\n",
      "langchain-aws 0.1.18 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Combining all installations into one cell\n",
    "!pip install --disable-pip-version-check -q pip --upgrade > /dev/null\n",
    "!pip install --disable-pip-version-check -q wrapt --upgrade > /dev/null\n",
    "!pip install --disable-pip-version-check -q awscli boto3\n",
    "!pip install --disable-pip-version-check -q sagemaker\n",
    "!pip install --disable-pip-version-check -q smdebug\n",
    "!pip install --disable-pip-version-check -q sagemaker-experiments\n",
    "!pip install --disable-pip-version-check -q PyAthena\n",
    "!pip install --disable-pip-version-check -q awswrangler\n",
    "!pip install --disable-pip-version-check -q matplotlib\n",
    "!pip install --disable-pip-version-check -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - zip\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libpng-1.6.45              |       h943b412_0         283 KB  conda-forge\n",
      "    torchvision-0.19.1         |cpu_py311h8c76117_3        10.0 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        10.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  zip                conda-forge/linux-64::zip-3.0-hd590300_3 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  amazon-sagemaker-~                     3.1.7-pyhd8ed1ab_0 --> 3.1.8-pyhd8ed1ab_0 \n",
      "  amazon_sagemaker_~                    0.1.13-pyhd8ed1ab_0 --> 0.1.14-pyhd8ed1ab_0 \n",
      "  aws-glue-sessions                      1.0.7-pyhd8ed1ab_0 --> 1.0.8-pyhd8ed1ab_0 \n",
      "  ca-certificates                      2024.8.30-hbcca054_0 --> 2024.12.14-hbcca054_0 \n",
      "  certifi                            2024.8.30-pyhd8ed1ab_0 --> 2024.12.14-pyhd8ed1ab_0 \n",
      "  conda                              24.9.2-py311h38be061_0 --> 24.11.3-py311h38be061_0 \n",
      "  jinja2                                 3.1.4-pyhd8ed1ab_1 --> 3.1.5-pyhd8ed1ab_0 \n",
      "  jupyter-ai                            2.28.3-pyhd8ed1ab_0 --> 2.28.5-pyhd8ed1ab_0 \n",
      "  jupyter-ai-magics                     2.28.3-pyhd8ed1ab_0 --> 2.28.5-pyhd8ed1ab_0 \n",
      "  jupyter-server-pr~                     4.4.0-pyhd8ed1ab_0 --> 4.4.0-pyhd8ed1ab_1 \n",
      "  jupyterlab                             4.2.6-pyhff2d567_0 --> 4.2.7-pyhd8ed1ab_0 \n",
      "  jupyterlab-git                        0.50.2-pyhd8ed1ab_0 --> 0.50.2-pyhd8ed1ab_1 \n",
      "  libmamba                                1.5.11-hf72d635_0 --> 1.5.12-h49b8a8d_0 \n",
      "  libmambapy                         1.5.11-py311h18a8eac_0 --> 1.5.12-py311hb3373dd_0 \n",
      "  libpng                                  1.6.44-hadc24fc_0 --> 1.6.45-h943b412_0 \n",
      "  matplotlib-base                     3.9.3-py311h2b939e6_0 --> 3.9.4-py311h2b939e6_0 \n",
      "  nodejs                                 20.18.0-hc55a1b2_0 --> 20.18.1-hc55a1b2_0 \n",
      "  openssl                                  3.4.0-hb9d3cd8_0 --> 3.4.0-h7b32b05_1 \n",
      "  pip                                   24.3.1-pyh8b19718_0 --> 24.3.1-pyh8b19718_2 \n",
      "  pyhive                                 0.7.0-pyhd8ed1ab_0 --> 0.7.0-pyhd8ed1ab_1 \n",
      "  python-lsp-server                     1.12.0-pyhd8ed1ab_0 --> 1.12.0-pyhff2d567_1 \n",
      "  python-lsp-server~                    1.12.0-pyhd8ed1ab_0 --> 1.12.0-pyhd8ed1ab_1 \n",
      "  sagemaker-code-ed~                       1.4.1-h3e77e23_0 --> 1.4.2-h3e77e23_0 \n",
      "  sagemaker-jupyter~                     0.3.4-pyhd8ed1ab_0 --> 0.3.5-pyhd8ed1ab_0 \n",
      "  sagemaker-jupyter~                     0.3.2-pyhd8ed1ab_0 --> 0.3.3-pyhd8ed1ab_0 \n",
      "  sagemaker-studio-~                     0.1.2-pyhd8ed1ab_0 --> 0.1.3-pyhd8ed1ab_0 \n",
      "  tf-keras                              2.17.0-pyhd8ed1ab_0 --> 2.17.0-pyhd8ed1ab_1 \n",
      "  torchvision                    0.19.1-cpu_py311hcef334a_1 --> 0.19.1-cpu_py311h8c76117_3 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "torchvision-0.19.1   | 10.0 MB   |                                       |   0% \n",
      "torchvision-0.19.1   | 10.0 MB   |                                       |   0% \u001b[A\n",
      "libpng-1.6.45        | 283 KB    | ##################################### | 100% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: / \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dependencies_passed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'setup_dependencies_passed' (bool)\n"
     ]
    }
   ],
   "source": [
    "%store setup_dependencies_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "s3_private_path_csv                   -> 's3://sagemaker-us-east-1-203012117619/assignment-\n",
      "setup_dependencies_passed             -> True\n",
      "setup_s3_bucket_passed                -> True\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Imports\n",
    "import boto3\n",
    "from botocore.client import ClientError\n",
    "import sagemaker\n",
    "from pyathena import connect\n",
    "import awswrangler as wr\n",
    "\n",
    "# Data Transformation Imports\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Misc Imports\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "s3 = boto3.Session().client(service_name=\"s3\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_s3_bucket_passed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bucket: sagemaker-us-east-1-203012117619\n"
     ]
    }
   ],
   "source": [
    "print(\"Default bucket: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '8Z5RE2061BKFHNG0', 'HostId': 's/+Zo9LR5eZFac0SgezBZHMgTUi1rqzKioXcclwz165ssZD9MHK98XK3kMMWbpeTsWDLow4Wv0c=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 's/+Zo9LR5eZFac0SgezBZHMgTUi1rqzKioXcclwz165ssZD9MHK98XK3kMMWbpeTsWDLow4Wv0c=', 'x-amz-request-id': '8Z5RE2061BKFHNG0', 'date': 'Mon, 20 Jan 2025 04:20:34 GMT', 'x-amz-bucket-region': 'us-east-1', 'x-amz-access-point-alias': 'false', 'content-type': 'application/xml', 'transfer-encoding': 'chunked', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'BucketRegion': 'us-east-1', 'AccessPointAlias': False}\n"
     ]
    }
   ],
   "source": [
    "response = None\n",
    "\n",
    "try:\n",
    "    response = s3.head_bucket(Bucket=bucket)\n",
    "    print(response)\n",
    "    setup_s3_bucket_passed = True\n",
    "except ClientError as e:\n",
    "    print(\"[ERROR] Cannot find bucket {} in {} due to {}.\".format(bucket, response, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'setup_s3_bucket_passed' (bool)\n"
     ]
    }
   ],
   "source": [
    "%store setup_s3_bucket_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "s3_private_path_csv                   -> 's3://sagemaker-us-east-1-203012117619/assignment-\n",
      "setup_dependencies_passed             -> True\n",
      "setup_s3_bucket_passed                -> True\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Dataset to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    setup_dependencies_passed\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN ALL NOTEBOOKS IN THE SETUP FOLDER FIRST. You are missing Setup Dependencies.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(setup_dependencies_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r setup_s3_bucket_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    setup_s3_bucket_passed\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN ALL NOTEBOOKS IN THE SETUP FOLDER FIRST. You are missing Setup S3 Bucket.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(setup_s3_bucket_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not setup_dependencies_passed:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN ALL NOTEBOOKS IN THE SETUP FOLDER FIRST. You are missing Setup Dependencies.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "if not setup_s3_bucket_passed:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN ALL NOTEBOOKS IN THE SETUP FOLDER FIRST. You are missing Setup S3 Bucket.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting S3 Destination Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-203012117619/assignment-2/csv\n"
     ]
    }
   ],
   "source": [
    "s3_private_path_csv = \"s3://{}/assignment-2/csv\".format(bucket)\n",
    "print(s3_private_path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 's3_private_path_csv' (str)\n"
     ]
    }
   ],
   "source": [
    "%store s3_private_path_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying Data from Local Directory to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./dataset.csv to s3://sagemaker-us-east-1-203012117619/assignment-2/csv/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp \"dataset.csv\" $s3_private_path_csv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Files in our Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-203012117619/assignment-2/csv\n"
     ]
    }
   ],
   "source": [
    "print(s3_private_path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-19 19:48:31    1048576 dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_private_path_csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-203012117619/assignment-2/?region=us-east-1&tab=overview\">S3 Bucket</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-{}-{}/assignment-2/?region={}&tab=overview\">S3 Bucket</a></b>'.format(\n",
    "            region, account_id, region\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Athena Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_create_athena_db_passed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"dsoaws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set S3 staging directory -- this is a temporary directory used for Athena queries\n",
    "s3_staging_dir = \"s3://{0}/athena/staging\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(region_name=region, s3_staging_dir=s3_staging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE DATABASE IF NOT EXISTS dsoaws\n"
     ]
    }
   ],
   "source": [
    "statement = \"CREATE DATABASE IF NOT EXISTS {}\".format(database_name)\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/618921652.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(statement, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(statement, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/3999478089.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_show = pd.read_sql(statement, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsoaws</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  database_name\n",
       "0       default\n",
       "1        dsoaws"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"SHOW DATABASES\"\n",
    "\n",
    "df_show = pd.read_sql(statement, conn)\n",
    "df_show.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database_name in df_show.values:\n",
    "    ingest_create_athena_db_passed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ingest_create_athena_db_passed' (bool)\n"
     ]
    }
   ],
   "source": [
    "%store ingest_create_athena_db_passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Data with Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Table from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Athena parameters\n",
    "database_name = \"dsoaws\"\n",
    "table_name_csv = \"assignment_2_dataset_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(region_name=region, s3_staging_dir=s3_staging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTERNAL TABLE IF NOT EXISTS dsoaws.assignment_2_dataset_csv(\n",
      "    index_col INT,\n",
      "    track_id STRING,\n",
      "    artists STRING,\n",
      "    album_name STRING,\n",
      "    track_name STRING,\n",
      "    popularity INT,\n",
      "    duration_ms INT,\n",
      "    explicit BOOLEAN,\n",
      "    danceability FLOAT,\n",
      "    energy FLOAT,\n",
      "    key INT,\n",
      "    loudness FLOAT,\n",
      "    mode INT,\n",
      "    speechiness FLOAT,\n",
      "    acousticness FLOAT,\n",
      "    instrumentalness FLOAT,\n",
      "    liveness FLOAT,\n",
      "    valence FLOAT,\n",
      "    tempo FLOAT,\n",
      "    time_signature INT,\n",
      "    track_genre STRING\n",
      ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\n' LOCATION 's3://sagemaker-us-east-1-203012117619/assignment-2/csv'\n",
      "TBLPROPERTIES ('skip.header.line.count'='1')\n"
     ]
    }
   ],
   "source": [
    "statement = \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {}.{}(\n",
    "    index_col INT,\n",
    "    track_id STRING,\n",
    "    artists STRING,\n",
    "    album_name STRING,\n",
    "    track_name STRING,\n",
    "    popularity INT,\n",
    "    duration_ms INT,\n",
    "    explicit BOOLEAN,\n",
    "    danceability FLOAT,\n",
    "    energy FLOAT,\n",
    "    key INT,\n",
    "    loudness FLOAT,\n",
    "    mode INT,\n",
    "    speechiness FLOAT,\n",
    "    acousticness FLOAT,\n",
    "    instrumentalness FLOAT,\n",
    "    liveness FLOAT,\n",
    "    valence FLOAT,\n",
    "    tempo FLOAT,\n",
    "    time_signature INT,\n",
    "    track_genre STRING\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\\\n' LOCATION '{}'\n",
    "TBLPROPERTIES ('skip.header.line.count'='1')\"\"\".format(\n",
    "    database_name, table_name_csv, s3_private_path_csv\n",
    ")\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/618921652.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(statement, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(statement, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/2201015668.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_show = pd.read_sql(statement, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tab_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assignment_2_dataset_csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tab_name\n",
       "0  assignment_2_dataset_csv"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"SHOW TABLES in {}\".format(database_name)\n",
    "\n",
    "df_show = pd.read_sql(statement, conn)\n",
    "df_show.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List artist, track_name, and popularity for songs that have a popularity greater than or equal to 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/3351755692.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  SQLQ1_show = pd.read_sql(SQLQ1,conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artists, track_name, popularity]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQLQ1 = f\"\"\"SELECT artists,track_name, popularity FROM {database_name}.{table_name_csv} WHERE popularity >= 99;\"\"\"\n",
    "SQLQ1_show = pd.read_sql(SQLQ1,conn)\n",
    "SQLQ1_show.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List artists with an average popularity of 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/1258578713.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  SQLQ2_show = pd.read_sql(SQLQ2,conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artists, average_popularity]\n",
       "Index: []"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQLQ2 = f\"\"\"\n",
    "SELECT \n",
    "    artists, \n",
    "    AVG(popularity) AS average_popularity \n",
    "FROM \n",
    "    {database_name}.{table_name_csv} \n",
    "GROUP BY \n",
    "    artists \n",
    "HAVING \n",
    "    AVG(popularity) = 92;\n",
    "\"\"\"\n",
    "\n",
    "SQLQ2_show = pd.read_sql(SQLQ2,conn)\n",
    "SQLQ2_show.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Top 10 most energetic genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/4072621192.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  SQLQ3_show = pd.read_sql(SQLQ3,conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_genre</th>\n",
       "      <th>avg_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black-metal</td>\n",
       "      <td>0.879181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alt-rock</td>\n",
       "      <td>0.755122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alternative</td>\n",
       "      <td>0.721058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afrobeat</td>\n",
       "      <td>0.702747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anime</td>\n",
       "      <td>0.677280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.540275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.440323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.439168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_genre  avg_energy\n",
       "0        0.104   54.000000\n",
       "1  black-metal    0.879181\n",
       "2     alt-rock    0.755122\n",
       "3  alternative    0.721058\n",
       "4     afrobeat    0.702747\n",
       "5        anime    0.677280\n",
       "6            4    0.540275\n",
       "7            1    0.452000\n",
       "8            3    0.440323\n",
       "9     acoustic    0.439168"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQLQ3 = f\"\"\"SELECT \n",
    "    track_genre, \n",
    "    AVG(energy) AS avg_energy \n",
    "FROM \n",
    "    {database_name}.{table_name_csv} \n",
    "GROUP BY \n",
    "    track_genre \n",
    "ORDER BY \n",
    "    avg_energy DESC \n",
    "LIMIT 10;\"\"\"\n",
    "\n",
    "SQLQ3_show = pd.read_sql(SQLQ3,conn)\n",
    "SQLQ3_show.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many tracks is Bad Bunny on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/965045587.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  SQLQ4_show = pd.read_sql(SQLQ4,conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_count\n",
       "0            0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQLQ4 = f\"\"\"SELECT \n",
    "    COUNT(*) AS track_count \n",
    "FROM \n",
    "    {database_name}.{table_name_csv} \n",
    "WHERE \n",
    "    artists LIKE '%Bad Bunny%';\"\"\"\n",
    "\n",
    "SQLQ4_show = pd.read_sql(SQLQ4,conn)\n",
    "SQLQ4_show.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the top 10 genres in terms of popularity sorted by their most popular track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/1114623197.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  SQLQ5_show = pd.read_sql(SQLQ5,conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_genre</th>\n",
       "      <th>max_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alternative</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alt-rock</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ambient</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anime</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acoustic</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>afrobeat</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black-metal</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>129.491</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125.925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>track_genre</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_genre  max_popularity\n",
       "0  alternative            93.0\n",
       "1     alt-rock            93.0\n",
       "2      ambient            84.0\n",
       "3        anime            83.0\n",
       "4     acoustic            82.0\n",
       "5     afrobeat            75.0\n",
       "6  black-metal            58.0\n",
       "7      129.491             NaN\n",
       "8      125.925             NaN\n",
       "9  track_genre             NaN"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQLQ5 = f\"\"\"SELECT \n",
    "    track_genre, \n",
    "    MAX(popularity) AS max_popularity \n",
    "FROM \n",
    "    {database_name}.{table_name_csv}\n",
    "GROUP BY \n",
    "    track_genre \n",
    "ORDER BY \n",
    "    max_popularity DESC \n",
    "LIMIT 10;\"\"\"\n",
    "\n",
    "SQLQ5_show = pd.read_sql(SQLQ5,conn)\n",
    "SQLQ5_show.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'QHT8Y125PHA05SHC',\n",
       "  'HostId': '49SUkuf1B7kbiKo3l+J7yG6y4Ba1K50SpPCkCxY4Gxfol7w8TBhstp6+Qhz0kmCkLHhOHp/0s8Y=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '49SUkuf1B7kbiKo3l+J7yG6y4Ba1K50SpPCkCxY4Gxfol7w8TBhstp6+Qhz0kmCkLHhOHp/0s8Y=',\n",
       "   'x-amz-request-id': 'QHT8Y125PHA05SHC',\n",
       "   'date': 'Mon, 20 Jan 2025 05:24:21 GMT',\n",
       "   'last-modified': 'Sun, 19 Jan 2025 19:48:31 GMT',\n",
       "   'etag': '\"42ff51fa674f918e1cec174245acbda2\"',\n",
       "   'x-amz-checksum-crc32': 'tT/7tA==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'content-type': 'text/csv',\n",
       "   'content-length': '1048576',\n",
       "   'server': 'AmazonS3'},\n",
       "  'ChecksumAlgorithm': 'crc32',\n",
       "  'RetryAttempts': 0},\n",
       " 'AcceptRanges': 'bytes',\n",
       " 'LastModified': datetime.datetime(2025, 1, 19, 19, 48, 31, tzinfo=tzutc()),\n",
       " 'ContentLength': 1048576,\n",
       " 'ETag': '\"42ff51fa674f918e1cec174245acbda2\"',\n",
       " 'ChecksumCRC32': 'tT/7tA==',\n",
       " 'ChecksumType': 'FULL_OBJECT',\n",
       " 'ContentType': 'text/csv',\n",
       " 'ServerSideEncryption': 'AES256',\n",
       " 'Metadata': {},\n",
       " 'Body': <botocore.httpchecksum.StreamingChecksumBody at 0x7f4ee0588490>}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = s3.get_object(Bucket=bucket,Key=\"assignment-2/csv/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_content = response['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(StringIO(csv_content))\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73.0</td>\n",
       "      <td>230666.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4.0</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55.0</td>\n",
       "      <td>149610.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4.0</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57.0</td>\n",
       "      <td>210826.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4.0</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71.0</td>\n",
       "      <td>201933.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3.0</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82.0</td>\n",
       "      <td>198853.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4.0</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                 artists  \\\n",
       "0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms explicit  danceability  \\\n",
       "0                      Comedy        73.0     230666.0    False         0.676   \n",
       "1            Ghost - Acoustic        55.0     149610.0    False         0.420   \n",
       "2              To Begin Again        57.0     210826.0    False         0.438   \n",
       "3  Can't Help Falling In Love        71.0     201933.0    False         0.266   \n",
       "4                     Hold On        82.0     198853.0    False         0.618   \n",
       "\n",
       "   energy  key  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0  0.4610  1.0    -6.746   0.0       0.1430        0.0322          0.000001   \n",
       "1  0.1660  1.0   -17.235   1.0       0.0763        0.9240          0.000006   \n",
       "2  0.3590  0.0    -9.734   1.0       0.0557        0.2100          0.000000   \n",
       "3  0.0596  0.0   -18.515   1.0       0.0363        0.9050          0.000071   \n",
       "4  0.4430  2.0    -9.681   1.0       0.0526        0.4690          0.000000   \n",
       "\n",
       "   liveness  valence    tempo  time_signature track_genre  \n",
       "0    0.3580    0.715   87.917             4.0    acoustic  \n",
       "1    0.1010    0.267   77.489             4.0    acoustic  \n",
       "2    0.1170    0.120   76.332             4.0    acoustic  \n",
       "3    0.1320    0.143  181.740             3.0    acoustic  \n",
       "4    0.0829    0.167  119.949             4.0    acoustic  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuploading Cleaned CSV File "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Step 4: Reupload the CSV to S3\n",
    "s3.put_object(Bucket=bucket, Key='assignment-2/csv/cleaned-dataset.csv', Body=csv_buffer.getvalue())\n",
    "print(\"File successfully updated and uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List artist, track_name, and popularity for songs that have a popularity greater than or equal to 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [artists, track_name, popularity]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "result = df[df['popularity'] >= 99][['artists', 'track_name', 'popularity']]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List artists with an average popularity of 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [artists, popularity]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('artists')['popularity'].mean().reset_index()\n",
    "\n",
    "# Filter for artists with an average popularity of 92\n",
    "result = grouped[grouped['popularity'] == 92]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Top 10 most energetic genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   track_genre    energy\n",
      "6  black-metal  0.877573\n",
      "2     alt-rock  0.754173\n",
      "3  alternative  0.720030\n",
      "1     afrobeat  0.702812\n",
      "5        anime  0.674108\n",
      "0     acoustic  0.435368\n",
      "4      ambient  0.237162\n"
     ]
    }
   ],
   "source": [
    "# Group by genre and calculate the average energy\n",
    "grouped = df.groupby('track_genre')['energy'].mean().reset_index()\n",
    "\n",
    "# Sort by average energy in descending order and get the top 10\n",
    "result = grouped.sort_values(by='energy', ascending=False).head(10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many tracks is Bad Bunny on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Bunny is on 0 tracks.\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Bad Bunny' is in the artists column and count them\n",
    "result = df[df['artists'].str.contains('Bad Bunny', na=False)]['track_id'].count()\n",
    "print(f\"Bad Bunny is on {result} tracks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the top 10 genres in terms of popularity sorted by their most popular track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   track_genre  popularity\n",
      "2     alt-rock        93.0\n",
      "3  alternative        93.0\n",
      "4      ambient        84.0\n",
      "5        anime        83.0\n",
      "0     acoustic        82.0\n",
      "1     afrobeat        75.0\n",
      "6  black-metal        58.0\n"
     ]
    }
   ],
   "source": [
    "# Group by genre and get the maximum popularity for each genre\n",
    "grouped = df.groupby('track_genre')['popularity'].max().reset_index()\n",
    "\n",
    "# Sort by the most popular track in descending order and get the top 10 genres\n",
    "result = grouped.sort_values(by='popularity', ascending=False).head(10)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
